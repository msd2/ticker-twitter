{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a65e030b-6449-4d3c-8cda-70517e4fda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import spacy\n",
    "from datetime import date\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import string\n",
    "from io import StringIO, BytesIO\n",
    "from urllib.request import Request, urlopen\n",
    "from functools import reduce, partial\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "from time import time\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', parser=True)\n",
    "\n",
    "\n",
    "def read_from_bucket(bucket):\n",
    "\n",
    "    \"\"\"\n",
    "    This concatenates all csv files in a bucket together.\n",
    "    Returns a single dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    frames = []\n",
    "    files  = list(bucket.list_blobs())\n",
    "    for file in files:\n",
    "        blob = bucket.blob(file.name)\n",
    "        data = pd.read_csv(BytesIO(blob.download_as_string()), encoding='utf-8')\n",
    "        frames.append(data)\n",
    "    data = pd.concat(frames)\n",
    "    return data\n",
    "\n",
    "\n",
    "def return_politician_handles(option='list'):\n",
    "    req = Request('https://www.politics-social.com/api/list/csv/followers', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    s=str(webpage,'utf-8')\n",
    "    data = StringIO(s) \n",
    "    df=pd.read_csv(data)\n",
    "    df['Name'] = df['Name'].apply(lambda x: x.rstrip())\n",
    "    df['Screen name'] = df['Screen name'].apply(lambda x: x[1:])\n",
    "    politician_handles = df['Screen name']\n",
    "    print('Politician twitter handles imported.\\n')\n",
    "\n",
    "    if option=='list':\n",
    "        return politician_handles\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "def deEmojify(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_hyperlinks(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[)(|!%?@#*,/:;…-]', ' ', text)\n",
    "    text = re.sub(r'&amp', 'and', text)\n",
    "    return text\n",
    "\n",
    "def fix_apostrophes(text):\n",
    "    text = re.sub(r'’', \"'\", text)\n",
    "    return text\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    text = re.sub(r'[\\t\\n\\r]', ' ', text)\n",
    "    return text\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "def strip_space(text):\n",
    "    return text.strip()\n",
    "\n",
    "def end_with_fullstop(text):\n",
    "#     print(text)\n",
    "    if len(text)>0 and text[-1]=='.':\n",
    "        return text\n",
    "    else:\n",
    "        return text + '.'\n",
    "\n",
    "def string_process(text):\n",
    "    func_list = [\n",
    "        deEmojify,\n",
    "        remove_hyperlinks,\n",
    "        remove_punctuation,\n",
    "        fix_apostrophes,\n",
    "        remove_whitespace,\n",
    "        normalize_whitespace,\n",
    "        strip_space,\n",
    "        end_with_fullstop\n",
    "    ]\n",
    "    text = reduce(lambda x, func: func(x), func_list, text)\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token for token in doc if not token.is_stop]\n",
    "    tokens = [token for token in tokens if token.pos_ not in ['PUNCT','SYM','NUM','PART','SPACE']]\n",
    "    tokens = [token for token in tokens if token.text not in [\n",
    "        \"n't\",\"'h\",'m','wh','%','rt',\"'s\",\"'ve\",\"'ll\",'’re',\n",
    "        \"'m\",'&',\"'ve\",\"'re\",'’ve','’ll','’s','’m','n’t','s.','c.','f.','m.'\n",
    "    ]]\n",
    "    tokens = [token.lemma_ for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7013779-0460-4bee-8bfd-5ee7410a5267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1442904820264804354</td>\n",
       "      <td>Very sorry to hear of the death of Roger Hunt,...</td>\n",
       "      <td>2021-09-28 17:31:31+00:00</td>\n",
       "      <td>BorisJohnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1442895964386197507</td>\n",
       "      <td>I'd urge everyone to go about their business i...</td>\n",
       "      <td>2021-09-28 16:56:20+00:00</td>\n",
       "      <td>BorisJohnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1442513824821751809</td>\n",
       "      <td>RT @RishiSunak: When we said we’d do whatever ...</td>\n",
       "      <td>2021-09-27 15:37:51+00:00</td>\n",
       "      <td>BorisJohnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1442062761761062920</td>\n",
       "      <td>It’s 75 years since the foundation of the Nati...</td>\n",
       "      <td>2021-09-26 09:45:29+00:00</td>\n",
       "      <td>BorisJohnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1442031671910486016</td>\n",
       "      <td>No words can adequately do justice to the debt...</td>\n",
       "      <td>2021-09-26 07:41:56+00:00</td>\n",
       "      <td>BorisJohnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1442904820264804354  Very sorry to hear of the death of Roger Hunt,...   \n",
       "1  1442895964386197507  I'd urge everyone to go about their business i...   \n",
       "2  1442513824821751809  RT @RishiSunak: When we said we’d do whatever ...   \n",
       "3  1442062761761062920  It’s 75 years since the foundation of the Nati...   \n",
       "4  1442031671910486016  No words can adequately do justice to the debt...   \n",
       "\n",
       "                     created          user  \n",
       "0  2021-09-28 17:31:31+00:00  BorisJohnson  \n",
       "1  2021-09-28 16:56:20+00:00  BorisJohnson  \n",
       "2  2021-09-27 15:37:51+00:00  BorisJohnson  \n",
       "3  2021-09-26 09:45:29+00:00  BorisJohnson  \n",
       "4  2021-09-26 07:41:56+00:00  BorisJohnson  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'uk-gov-tweets-14289'\n",
    "storage_client = storage.Client.from_service_account_json('creds.json')\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "data = read_from_bucket(bucket=bucket)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b2a1b2-0dcd-428c-b23b-2e1ef1caa80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['text'].apply(string_process)\n",
    "corpus = corpus.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9618b23a-e956-4241-9c5f-79b7fc42628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('tokenized_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd9da542-0838-4f9f-b728-a1c3f4896b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [sorry, hear, death, roger, hunt, legendary, g...\n",
       "1        [would, urge, business, normal, way, fill, need]\n",
       "2       [rishisunak, say, would, take, mean, story, fu...\n",
       "3       [year, foundation, national, blood, transfusio...\n",
       "4       [word, adequately, justice, debt, nation, owe,...\n",
       "                              ...                        \n",
       "3078    [deputy, prime, minister, justice, secretary, ...\n",
       "3079    [politicsjoe_uk, eton, millionaire, care, disa...\n",
       "3080    [teacher, encourage, believe, forward, stand, ...\n",
       "3081                                    [detail, protest]\n",
       "3082    [uber, mega, corporation, worth, billion, poun...\n",
       "Name: text, Length: 32539, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76bca16f-fbab-4883-83c5-8728477e7c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdunford/opt/anaconda3/envs/tweet_project/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b50e73bf-b443-4e4e-b617-a67857c6839b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0a49a4b-74a6-4036-89e1-4d137a54df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:38:11: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.03)', 'datetime': '2021-10-09T10:38:11.313851', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=5,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a1cb5e1-4c4b-401b-b5a2-770ae8237213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:38:13: collecting all words and their counts\n",
      "INFO - 10:38:13: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 10:38:13: PROGRESS: at sentence #10000, processed 127986 words, keeping 18002 word types\n",
      "INFO - 10:38:14: PROGRESS: at sentence #20000, processed 256343 words, keeping 27954 word types\n",
      "INFO - 10:38:14: PROGRESS: at sentence #30000, processed 377485 words, keeping 35347 word types\n",
      "INFO - 10:38:14: collected 36841 word types from a corpus of 409026 raw words and 32539 sentences\n",
      "INFO - 10:38:14: Creating a fresh vocabulary\n",
      "INFO - 10:38:14: Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 7734 unique words (20.992915501750765%% of original 36841, drops 29107)', 'datetime': '2021-10-09T10:38:14.166368', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 10:38:14: Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 365095 word corpus (89.25960696875015%% of original 409026, drops 43931)', 'datetime': '2021-10-09T10:38:14.167187', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 10:38:14: deleting the raw counts dictionary of 36841 items\n",
      "INFO - 10:38:14: sample=6e-05 downsamples 1189 most-common words\n",
      "INFO - 10:38:14: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 198155.82552920605 word corpus (54.3%% of prior 365095)', 'datetime': '2021-10-09T10:38:14.218684', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 10:38:14: estimated required memory for 7734 words and 300 dimensions: 22428600 bytes\n",
      "INFO - 10:38:14: resetting layer weights\n",
      "INFO - 10:38:14: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-10-09T10:38:14.316749', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(corpus, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62fa29b2-2dc5-4b90-b862-76087d8b8b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:38:17: Word2Vec lifecycle event {'msg': 'training model with 3 workers on 7734 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2', 'datetime': '2021-10-09T10:38:17.966961', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO - 10:38:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:18: EPOCH - 1 : training on 409026 raw words (197897 effective words) took 0.7s, 292974 effective words/s\n",
      "INFO - 10:38:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:19: EPOCH - 2 : training on 409026 raw words (198274 effective words) took 0.6s, 358508 effective words/s\n",
      "INFO - 10:38:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:20: EPOCH - 3 : training on 409026 raw words (197640 effective words) took 0.9s, 232125 effective words/s\n",
      "INFO - 10:38:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:20: EPOCH - 4 : training on 409026 raw words (198526 effective words) took 0.6s, 344549 effective words/s\n",
      "INFO - 10:38:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:21: EPOCH - 5 : training on 409026 raw words (198406 effective words) took 0.7s, 285849 effective words/s\n",
      "INFO - 10:38:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:22: EPOCH - 6 : training on 409026 raw words (198244 effective words) took 1.0s, 205191 effective words/s\n",
      "INFO - 10:38:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:23: EPOCH - 7 : training on 409026 raw words (198098 effective words) took 0.8s, 233229 effective words/s\n",
      "INFO - 10:38:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:23: EPOCH - 8 : training on 409026 raw words (197843 effective words) took 0.7s, 272536 effective words/s\n",
      "INFO - 10:38:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:24: EPOCH - 9 : training on 409026 raw words (198178 effective words) took 0.8s, 242566 effective words/s\n",
      "INFO - 10:38:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:25: EPOCH - 10 : training on 409026 raw words (198623 effective words) took 0.7s, 278971 effective words/s\n",
      "INFO - 10:38:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:26: EPOCH - 11 : training on 409026 raw words (198180 effective words) took 0.7s, 292803 effective words/s\n",
      "INFO - 10:38:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:26: EPOCH - 12 : training on 409026 raw words (198148 effective words) took 0.7s, 302303 effective words/s\n",
      "INFO - 10:38:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:27: EPOCH - 13 : training on 409026 raw words (197895 effective words) took 0.7s, 273098 effective words/s\n",
      "INFO - 10:38:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:28: EPOCH - 14 : training on 409026 raw words (198238 effective words) took 0.7s, 283671 effective words/s\n",
      "INFO - 10:38:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:29: EPOCH - 15 : training on 409026 raw words (198497 effective words) took 0.8s, 249841 effective words/s\n",
      "INFO - 10:38:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:29: EPOCH - 16 : training on 409026 raw words (198344 effective words) took 0.6s, 320011 effective words/s\n",
      "INFO - 10:38:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:30: EPOCH - 17 : training on 409026 raw words (198095 effective words) took 0.8s, 255776 effective words/s\n",
      "INFO - 10:38:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:31: EPOCH - 18 : training on 409026 raw words (198212 effective words) took 0.6s, 307138 effective words/s\n",
      "INFO - 10:38:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:32: EPOCH - 19 : training on 409026 raw words (198292 effective words) took 0.8s, 234271 effective words/s\n",
      "INFO - 10:38:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:32: EPOCH - 20 : training on 409026 raw words (198591 effective words) took 0.9s, 223415 effective words/s\n",
      "INFO - 10:38:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:33: EPOCH - 21 : training on 409026 raw words (198298 effective words) took 0.7s, 276030 effective words/s\n",
      "INFO - 10:38:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:34: EPOCH - 22 : training on 409026 raw words (197983 effective words) took 0.9s, 228964 effective words/s\n",
      "INFO - 10:38:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:35: EPOCH - 23 : training on 409026 raw words (198466 effective words) took 0.6s, 334884 effective words/s\n",
      "INFO - 10:38:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:35: EPOCH - 24 : training on 409026 raw words (198228 effective words) took 0.8s, 262272 effective words/s\n",
      "INFO - 10:38:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:36: EPOCH - 25 : training on 409026 raw words (198192 effective words) took 0.5s, 378884 effective words/s\n",
      "INFO - 10:38:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:36: EPOCH - 26 : training on 409026 raw words (197934 effective words) took 0.5s, 367296 effective words/s\n",
      "INFO - 10:38:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:37: EPOCH - 27 : training on 409026 raw words (198670 effective words) took 0.9s, 232633 effective words/s\n",
      "INFO - 10:38:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:38: EPOCH - 28 : training on 409026 raw words (198501 effective words) took 0.5s, 363316 effective words/s\n",
      "INFO - 10:38:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:38: EPOCH - 29 : training on 409026 raw words (197671 effective words) took 0.5s, 395375 effective words/s\n",
      "INFO - 10:38:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:38:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:38:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:38:39: EPOCH - 30 : training on 409026 raw words (198084 effective words) took 0.7s, 284879 effective words/s\n",
      "INFO - 10:38:39: Word2Vec lifecycle event {'msg': 'training on 12270780 raw words (5946248 effective words) took 21.6s, 274680 effective words/s', 'datetime': '2021-10-09T10:38:39.617392', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.36 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(corpus, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afce2897-5a1d-4c84-9b9f-b79a6cc5fe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eton', 0.9443747997283936),\n",
       " ('politicsjoe_uk', 0.8493973016738892),\n",
       " ('landlord', 0.8288161754608154),\n",
       " ('hike', 0.7386841177940369),\n",
       " ('renter', 0.7367849349975586),\n",
       " ('arrear', 0.7354673147201538),\n",
       " ('socialcare', 0.7239164710044861),\n",
       " ('andrew_harrop', 0.7214705944061279),\n",
       " ('rent', 0.7198046445846558),\n",
       " ('clobber', 0.7147722244262695)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['millionaire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bbb83bd-332a-433f-ab89-2af88d0ce1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17753191"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('national', 'pride')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce60b005-6e44-4d6e-8367-fbe20a524dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sorry',\n",
       "  'hear',\n",
       "  'death',\n",
       "  'roger',\n",
       "  'hunt',\n",
       "  'legendary',\n",
       "  'goalscorer',\n",
       "  'member',\n",
       "  'magnificent',\n",
       "  'squad',\n",
       "  'take',\n",
       "  'england',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'victory',\n",
       "  'thought',\n",
       "  'family',\n",
       "  'friend',\n",
       "  'fan'],\n",
       " ['would', 'urge', 'business', 'normal', 'way', 'fill', 'need'],\n",
       " ['rishisunak', 'say', 'would', 'take', 'mean', 'story', 'furlough'],\n",
       " ['year',\n",
       "  'foundation',\n",
       "  'national',\n",
       "  'blood',\n",
       "  'transfusion',\n",
       "  'service',\n",
       "  'time',\n",
       "  'selfless',\n",
       "  'blood',\n",
       "  'donor',\n",
       "  'save',\n",
       "  'improve',\n",
       "  'life',\n",
       "  'people',\n",
       "  'hour',\n",
       "  'need',\n",
       "  'would',\n",
       "  'encourage',\n",
       "  'blood',\n",
       "  'donor',\n",
       "  'lifesav'],\n",
       " ['word',\n",
       "  'adequately',\n",
       "  'justice',\n",
       "  'debt',\n",
       "  'nation',\n",
       "  'owe',\n",
       "  'fall',\n",
       "  'police',\n",
       "  'officer',\n",
       "  'dedication',\n",
       "  'willingness',\n",
       "  'run',\n",
       "  'danger',\n",
       "  'simply',\n",
       "  'able',\n",
       "  'live',\n",
       "  'life',\n",
       "  'safety',\n",
       "  'security',\n",
       "  'grant',\n",
       "  'npmd21']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e876f2b1-4644-4ba6-b8e5-e3f1d96e293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:35:21: Word2Vec lifecycle event {'fname_or_handle': 'uk_politics_w2v.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-10-09T10:35:21.974485', 'gensim': '4.0.1', 'python': '3.7.11 (default, Jul 27 2021, 07:03:16) \\n[Clang 10.0.0 ]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'saving'}\n",
      "INFO - 10:35:21: not storing attribute cum_table\n",
      "INFO - 10:35:21: saved uk_politics_w2v.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save('uk_politics_w2v.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
